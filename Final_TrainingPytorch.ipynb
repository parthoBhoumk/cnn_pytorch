{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d60c5bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from IPython.display import display, clear_output\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "\n",
    "from itertools import product\n",
    "from collections import namedtuple\n",
    "from collections import OrderedDict\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network,self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels= 1, out_channels= 6 , kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels= 6, out_channels= 12 , kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features= 12*4*4 , out_features= 120)\n",
    "        self.fc2 = nn.Linear(in_features= 120, out_features= 60)\n",
    "        self.out = nn.Linear(in_features= 60, out_features= 10)\n",
    "\n",
    "    def forward(self,t):\n",
    "        \n",
    "        #1 inpput layer \n",
    "        \n",
    "        t = t\n",
    "        \n",
    "        #2 hidden conv layer\n",
    "        \n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size = 2 , stride = 2)\n",
    "        \n",
    "        #3 hidden conv layer \n",
    "        \n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size = 2 , stride = 2)\n",
    "        \n",
    "        #4 Linear layer \n",
    "        \n",
    "        t = t.reshape(-1, 12*4*4)     #flattening is hapening here\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "        \n",
    "        #5 Linear layer \n",
    "        \n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        #6 output layer\n",
    "        \n",
    "        t = self.out(t)\n",
    "        # t = F.softmax(t,dim = 0)    but this line is not required because we will predict the output later and softmax will be used explicitly later\n",
    "        return t\n",
    "        \n",
    "#loading data from url of Mnist\n",
    "\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "        root = './data'\n",
    "        ,train = True\n",
    "        ,download=True\n",
    "        ,transform = transforms.Compose([\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8976e52",
   "metadata": {},
   "source": [
    "# Building two classes Runbuilder and Run manager "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2900ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunBuilder():\n",
    "    @staticmethod\n",
    "    \n",
    "    def get_runs(params):\n",
    "        \n",
    "        \n",
    "        Run = namedtuple('Run',params.keys())\n",
    "        \n",
    "        runs = []\n",
    "        \n",
    "        for v in product(*params.values()):\n",
    "            runs.append(Run(*v))\n",
    "        return runs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd2b974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunManager():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.epoch_count = 0               #initializing the class to keep track of some attributes mentioned here\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        self.epoch_start_time = None\n",
    "        \n",
    "        self.run_count = 0                      #gives us the run number\n",
    "        \n",
    "        self.run_parameters = None         #This is the run definition in terms for the run parameters.\n",
    "                                            #It's value will be one of the runs returned by the RunBuilder class.\"\"\"\n",
    "        \n",
    "        self.run_data = []               #list we'll use to keep track of the parameter values and the results\n",
    "                                            #of each epoch for each run, and so we'll see that we add a value to this list for each epoch\"\"\"\n",
    "        \n",
    "        self.run_start_time = None                 # calculate the run time\n",
    "        \n",
    "        self.network = None\n",
    "        self.loader = None\n",
    "        self.tb = None\n",
    "    \n",
    "        \n",
    "        \n",
    "    # now lets make the begin run and end run methodss here to describe whats going on\n",
    "        \n",
    "    def begin_run(self,run,network,loader):\n",
    "\n",
    "        self.run_start_time = time.time()\n",
    "        self.run_count +=1\n",
    "        self.run_parameters = run\n",
    "\n",
    "        self.network = network\n",
    "        self.loader = loader\n",
    "        self.tb = SummaryWriter(comment= f'{run}')\n",
    "\n",
    "        images, labels = next(iter(self.loader))\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "        self.tb.add_image('images', grid)\n",
    "        self.tb.add_graph(self.network, images)\n",
    "\n",
    "\n",
    "\n",
    "    def end_run(self):\n",
    "        self.tb.close()\n",
    "        self.epoch_count = 0    # the run is done for aparticular choice of hyperparameter so epochs will go to zero for the next run of other hyper parameters \n",
    "\n",
    "\n",
    "\n",
    "    #Now we define the methods for the begin epochs and end epochs\n",
    "\n",
    "\n",
    "    def begin_epoch(self):\n",
    "\n",
    "        self.epoch_start_time = time.time()\n",
    "        self.epoch_count += 1\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "\n",
    "    def end_epoch(self):\n",
    "\n",
    "        epoch_delay = time.time() - self.epoch_start_time\n",
    "        run_delay = time.time() - self.run_start_time\n",
    "        \n",
    "        loss = self.epoch_loss/len(self.loader.dataset)\n",
    "        accuracy =self.epoch_num_correct/len(self.loader.dataset)\n",
    "        self.tb.add_scalar(\"Loss\", loss , self.epoch_count)\n",
    "        self.tb.add_scalar(\"Acuracy\", accuracy , self.epoch_count)\n",
    "        \n",
    "        for name,param in self.network.named_parameters():\n",
    "            self.tb.add_histogram(name , param, self.epoch_count)\n",
    "            self.tb.add_histogram(f'{name}.grad' , param.grad, self.epoch_count)\n",
    "        \n",
    "        \n",
    "        results = OrderedDict()\n",
    "        results[\"run\"] = self.run_count\n",
    "        results[\"epoch\"] = self.epoch_count\n",
    "        results['loss'] = loss\n",
    "        results[\"accuracy\"] = accuracy\n",
    "        results['epoch duration'] = epoch_delay\n",
    "        results['run duration'] = run_delay\n",
    "        \n",
    "        for k,v in self.run_parameters._asdict().items(): results[k] = v   #we iterate over the keys and values inside our run parameters adding them to the results dictionary. This will allow us to see the parameters that are associated with the performance results.\n",
    "        self.run_data.append(results)\n",
    "        \n",
    "        df = pd.DataFrame.from_dict(self.run_data,orient = 'columns')\n",
    "            \n",
    "        clear_output(wait=True)                #for jupyter notebook only\n",
    "        display(df)\n",
    "        \n",
    "\n",
    "    def track_loss(self,loss,batch):\n",
    "        self.epoch_loss += loss.item()*batch[0].shape[0]\n",
    "        \n",
    "        \n",
    "\n",
    "    def track_num_currect(self,preds,lables):\n",
    "        self.epoch_num_correct += self._get_num_correct(preds,labels)\n",
    "        \n",
    "\n",
    "        \n",
    "    def _get_num_correct(self,preds,labels):\n",
    "        return preds.argmax(dim =1).eq(labels).sum().item()\n",
    "    \n",
    "    \n",
    "    \n",
    "    def save(self, fileName):\n",
    "        pd.DataFrame.from_dict(\n",
    "            self.run_data, orient='columns'\n",
    "        ).to_csv(f'{fileName}.csv')\n",
    "\n",
    "        with open(f'{fileName}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.run_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb425f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>epoch duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>num_workers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.020335</td>\n",
       "      <td>0.611400</td>\n",
       "      <td>12.995622</td>\n",
       "      <td>35.037864</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.566733</td>\n",
       "      <td>0.780500</td>\n",
       "      <td>11.674317</td>\n",
       "      <td>46.916633</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.466057</td>\n",
       "      <td>0.826583</td>\n",
       "      <td>12.923108</td>\n",
       "      <td>59.958214</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.399585</td>\n",
       "      <td>0.854083</td>\n",
       "      <td>12.007528</td>\n",
       "      <td>72.071428</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.875552</td>\n",
       "      <td>0.673050</td>\n",
       "      <td>8.622833</td>\n",
       "      <td>10.039491</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.478960</td>\n",
       "      <td>0.822233</td>\n",
       "      <td>8.965144</td>\n",
       "      <td>19.148097</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.393968</td>\n",
       "      <td>0.855867</td>\n",
       "      <td>9.748299</td>\n",
       "      <td>29.057053</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.350546</td>\n",
       "      <td>0.871333</td>\n",
       "      <td>10.917571</td>\n",
       "      <td>40.172164</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.958595</td>\n",
       "      <td>0.629567</td>\n",
       "      <td>12.420371</td>\n",
       "      <td>13.909063</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.535456</td>\n",
       "      <td>0.786833</td>\n",
       "      <td>11.969656</td>\n",
       "      <td>26.044218</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.451980</td>\n",
       "      <td>0.827017</td>\n",
       "      <td>11.255926</td>\n",
       "      <td>37.469929</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.390889</td>\n",
       "      <td>0.856333</td>\n",
       "      <td>10.078024</td>\n",
       "      <td>47.712930</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    run  epoch      loss  accuracy  epoch duration  run duration    lr  \\\n",
       "0     1      1  1.020335  0.611400       12.995622     35.037864  0.01   \n",
       "1     1      2  0.566733  0.780500       11.674317     46.916633  0.01   \n",
       "2     1      3  0.466057  0.826583       12.923108     59.958214  0.01   \n",
       "3     1      4  0.399585  0.854083       12.007528     72.071428  0.01   \n",
       "4     2      1  0.875552  0.673050        8.622833     10.039491  0.01   \n",
       "5     2      2  0.478960  0.822233        8.965144     19.148097  0.01   \n",
       "6     2      3  0.393968  0.855867        9.748299     29.057053  0.01   \n",
       "7     2      4  0.350546  0.871333       10.917571     40.172164  0.01   \n",
       "8     3      1  0.958595  0.629567       12.420371     13.909063  0.01   \n",
       "9     3      2  0.535456  0.786833       11.969656     26.044218  0.01   \n",
       "10    3      3  0.451980  0.827017       11.255926     37.469929  0.01   \n",
       "11    3      4  0.390889  0.856333       10.078024     47.712930  0.01   \n",
       "\n",
       "    batch_size  num_workers  \n",
       "0         1000            0  \n",
       "1         1000            0  \n",
       "2         1000            0  \n",
       "3         1000            0  \n",
       "4         1000            1  \n",
       "5         1000            1  \n",
       "6         1000            1  \n",
       "7         1000            1  \n",
       "8         1000            4  \n",
       "9         1000            4  \n",
       "10        1000            4  \n",
       "11        1000            4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = OrderedDict(\n",
    "    lr = [.01,.001]\n",
    "    ,batch_size = [1000, 10000],\n",
    "    num_workers = [0,1,4]\n",
    "    \n",
    ")\n",
    "epochs = 4\n",
    "m = RunManager()\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    my_net = Network()\n",
    "    loader = torch.utils.data.DataLoader(train_set, batch_size= run.batch_size, num_workers = run.num_workers)\n",
    "    optimizer = optim.Adam(my_net.parameters(), lr = run.lr)\n",
    "    \n",
    "    m.begin_run(run,my_net,loader)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        m.begin_epoch()\n",
    "        \n",
    "        for batch in loader:\n",
    "            images,labels = batch\n",
    "            preds  = my_net(images)\n",
    "            loss = F.cross_entropy(preds,labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            m.track_loss(loss,batch)\n",
    "            m.track_num_currect(preds,labels)\n",
    "        m.end_epoch()\n",
    "    m.end_run()\n",
    "m.save('first_run_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cc6a59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
