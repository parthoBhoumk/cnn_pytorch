{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7be08691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import pandas  as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "torch.set_printoptions(linewidth=120)\n",
    "torch.set_grad_enabled(True)\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54d26128",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network,self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels= 1, out_channels= 6 , kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels= 6, out_channels= 12 , kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features= 12*4*4 , out_features= 120)\n",
    "        self.fc2 = nn.Linear(in_features= 120, out_features= 60)\n",
    "        self.out = nn.Linear(in_features= 60, out_features= 10)\n",
    "\n",
    "    def forward(self,t):\n",
    "        \n",
    "        #1 inpput layer \n",
    "        \n",
    "        t = t\n",
    "        \n",
    "        #2 hidden conv layer\n",
    "        \n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size = 2 , stride = 2)\n",
    "        \n",
    "        #3 hidden conv layer \n",
    "        \n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size = 2 , stride = 2)\n",
    "        \n",
    "        #4 Linear layer \n",
    "        \n",
    "        t = t.reshape(-1, 12*4*4)     #flattening is hapening here\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "        \n",
    "        #5 Linear layer \n",
    "        \n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        #6 output layer\n",
    "        \n",
    "        t = self.out(t)\n",
    "        # t = F.softmax(t,dim = 0)    but this line is not required because we will predict the output later and softmax will be used explicitly later\n",
    "        return t\n",
    "        \n",
    "#loading data from url of Mnist\n",
    "\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "        root = './data'\n",
    "        ,train = True\n",
    "        ,download=True\n",
    "        ,transform = transforms.Compose([\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "    \n",
    ")\n",
    "\n",
    "        \n",
    "data_loader = torch.utils.data.DataLoader(train_set,\n",
    "                    batch_size= 100                  \n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1098fa67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[100, 1000, 10000], [0.01, 0.001], [True, False]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "parameters = dict(\n",
    "             batch_size = [100,1000,10000],\n",
    "lr = [.01,.001],\n",
    "shuffle = [True,False]\n",
    ")\n",
    "param_values = [v for v in parameters.values()]\n",
    "param_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71896f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds,labels):\n",
    "    \n",
    "    return preds.argmax(dim = 1).eq(labels).sum().item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a75ddca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.01 True\n",
      "100 0.01 False\n",
      "100 0.001 True\n",
      "100 0.001 False\n",
      "1000 0.01 True\n",
      "1000 0.01 False\n",
      "1000 0.001 True\n",
      "1000 0.001 False\n",
      "10000 0.01 True\n",
      "10000 0.01 False\n",
      "10000 0.001 True\n",
      "10000 0.001 False\n"
     ]
    }
   ],
   "source": [
    "for batch_size,lr,shuffle in product(*param_values):\n",
    "    print(batch_size,lr,shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92b9737c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.01 True\n",
      "epoch: 0 total loss: 36440.217581391335 total correct: 46108\n",
      "epoch: 1 total loss: 23586.867792904377 total correct: 51198\n",
      "epoch: 2 total loss: 21597.924087941647 total correct: 51903\n",
      "100 0.01 False\n",
      "epoch: 0 total loss: 21190.988355875015 total correct: 52044\n",
      "epoch: 1 total loss: 20417.86715835333 total correct: 52312\n",
      "epoch: 2 total loss: 19859.13606584072 total correct: 52569\n",
      "100 0.001 True\n",
      "epoch: 0 total loss: 16326.094368845224 total correct: 53832\n",
      "epoch: 1 total loss: 15301.605065912008 total correct: 54114\n",
      "epoch: 2 total loss: 14822.40756303072 total correct: 54273\n",
      "100 0.001 False\n",
      "epoch: 0 total loss: 14477.373493462801 total correct: 54384\n",
      "epoch: 1 total loss: 14109.046341478825 total correct: 54508\n",
      "epoch: 2 total loss: 13822.247599065304 total correct: 54589\n",
      "1000 0.01 True\n",
      "epoch: 0 total loss: 15180.344849824905 total correct: 54101\n",
      "epoch: 1 total loss: 14249.944567680359 total correct: 54500\n",
      "epoch: 2 total loss: 14089.283168315887 total correct: 54559\n",
      "1000 0.01 False\n",
      "epoch: 0 total loss: 14287.721782922745 total correct: 54476\n",
      "epoch: 1 total loss: 13716.224789619446 total correct: 54684\n",
      "epoch: 2 total loss: 13424.29931461811 total correct: 54811\n",
      "1000 0.001 True\n",
      "epoch: 0 total loss: 12129.506960511208 total correct: 55247\n",
      "epoch: 1 total loss: 11577.261909842491 total correct: 55526\n",
      "epoch: 2 total loss: 11447.738066315651 total correct: 55563\n",
      "1000 0.001 False\n",
      "epoch: 0 total loss: 11400.761067867279 total correct: 55574\n",
      "epoch: 1 total loss: 11252.767458558083 total correct: 55630\n",
      "epoch: 2 total loss: 11144.912093877792 total correct: 55684\n",
      "10000 0.01 True\n",
      "epoch: 0 total loss: 15601.136237382889 total correct: 54111\n",
      "epoch: 1 total loss: 13112.049549818039 total correct: 54892\n",
      "epoch: 2 total loss: 12149.218171834946 total correct: 55301\n",
      "10000 0.01 False\n",
      "epoch: 0 total loss: 13062.75263428688 total correct: 54927\n",
      "epoch: 1 total loss: 11923.859715461731 total correct: 55344\n",
      "epoch: 2 total loss: 11335.251480340958 total correct: 55597\n",
      "10000 0.001 True\n",
      "epoch: 0 total loss: 10891.422927379608 total correct: 55740\n",
      "epoch: 1 total loss: 10708.553493022919 total correct: 55831\n",
      "epoch: 2 total loss: 10603.578686714172 total correct: 55853\n",
      "10000 0.001 False\n",
      "epoch: 0 total loss: 10611.301064491272 total correct: 55864\n",
      "epoch: 1 total loss: 10496.36796116829 total correct: 55914\n",
      "epoch: 2 total loss: 10431.228429079056 total correct: 55955\n"
     ]
    }
   ],
   "source": [
    "test_net = Network()\n",
    "for batch_size,lr,shuffle in product(*param_values):\n",
    "    print(batch_size,lr,shuffle)\n",
    "    comment = f'batch size = {batch_size},lr = {lr},shuffle = {shuffle}'\n",
    "    \n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size ,shuffle=shuffle)\n",
    "    images,labels = next(iter(train_loader))\n",
    "    grid = torchvision.utils.make_grid(images)\n",
    "    \n",
    "\n",
    "    tb = SummaryWriter(comment = comment)\n",
    "    tb.add_image('images',grid)\n",
    "    tb.add_graph(test_net,images)\n",
    "\n",
    "    optimizer = optim.Adam(test_net.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "    for epoch in range(3):\n",
    "\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        for batch in train_loader:                      # Get Batch\n",
    "            images, labels = batch\n",
    "\n",
    "            preds = test_net(images) # Pass Batch\n",
    "            loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward() # Calculate Gradients\n",
    "            optimizer.step() # Update Weights\n",
    "\n",
    "            total_loss += loss.item()*images.shape[0]               #using it to generalise the loss for different batch sizes\n",
    "            total_correct += get_num_correct(preds,labels)\n",
    "\n",
    "        tb.add_scalar(\"loss\",total_loss,epoch)\n",
    "        tb.add_scalar(\"total correct\", total_correct,epoch)\n",
    "        tb.add_scalar(\"Accuracy\", total_correct/len(train_set), epoch)\n",
    "\n",
    "        tb.add_histogram(\"conv1 bias\", test_net.conv1.bias, epoch)\n",
    "        tb.add_histogram(\"conv1.weight\", test_net.conv1.weight,epoch)\n",
    "        tb.add_histogram(\"conv1.weight.grad\", test_net.conv1.weight.grad,epoch)\n",
    "\n",
    "        print(\"epoch:\", epoch  , \"total loss:\", total_loss, \"total correct:\" ,total_correct )\n",
    "\n",
    "tb.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882dcd2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
