{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d60c5bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from IPython.display import display, clear_output\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "\n",
    "from itertools import product\n",
    "from collections import namedtuple\n",
    "from collections import OrderedDict\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network,self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels= 1, out_channels= 6 , kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels= 6, out_channels= 12 , kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features= 12*4*4 , out_features= 120)\n",
    "        self.fc2 = nn.Linear(in_features= 120, out_features= 60)\n",
    "        self.out = nn.Linear(in_features= 60, out_features= 10)\n",
    "\n",
    "    def forward(self,t):\n",
    "        \n",
    "        #1 inpput layer \n",
    "        \n",
    "        t = t\n",
    "        \n",
    "        #2 hidden conv layer\n",
    "        \n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size = 2 , stride = 2)\n",
    "        \n",
    "        #3 hidden conv layer \n",
    "        \n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size = 2 , stride = 2)\n",
    "        \n",
    "        #4 Linear layer \n",
    "        \n",
    "        t = t.reshape(-1, 12*4*4)     #flattening is hapening here\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "        \n",
    "        #5 Linear layer \n",
    "        \n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        #6 output layer\n",
    "        \n",
    "        t = self.out(t)\n",
    "        # t = F.softmax(t,dim = 0)    but this line is not required because we will predict the output later and softmax will be used explicitly later\n",
    "        return t\n",
    "        \n",
    "#loading data from url of Mnist\n",
    "\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "        root = './data'\n",
    "        ,train = True\n",
    "        ,download=True\n",
    "        ,transform = transforms.Compose([\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8976e52",
   "metadata": {},
   "source": [
    "# Building two classes Runbuilder and Run manager "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2900ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunBuilder():\n",
    "    @staticmethod\n",
    "    \n",
    "    def get_runs(params):\n",
    "        \n",
    "        \n",
    "        Run = namedtuple('Run',params.keys())\n",
    "        \n",
    "        runs = []\n",
    "        \n",
    "        for v in product(*params.values()):\n",
    "            runs.append(Run(*v))\n",
    "        return runs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd2b974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunManager():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.epoch_count = 0               #initializing the class to keep track of some attributes mentioned here\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        self.epoch_start_time = None\n",
    "        \n",
    "        self.run_count = 0                      #gives us the run number\n",
    "        \n",
    "        self.run_parameters = None         #This is the run definition in terms for the run parameters.\n",
    "                                            #It's value will be one of the runs returned by the RunBuilder class.\"\"\"\n",
    "        \n",
    "        self.run_data = []               #list we'll use to keep track of the parameter values and the results\n",
    "                                            #of each epoch for each run, and so we'll see that we add a value to this list for each epoch\"\"\"\n",
    "        \n",
    "        self.run_start_time = None                 # calculate the run time\n",
    "        \n",
    "        self.network = None\n",
    "        self.loader = None\n",
    "        self.tb = None\n",
    "    \n",
    "        \n",
    "        \n",
    "    # now lets make the begin run and end run methodss here to describe whats going on\n",
    "        \n",
    "    def begin_run(self,run,network,loader):\n",
    "\n",
    "        self.run_start_time = time.time()\n",
    "        self.run_count +=1\n",
    "        self.run_parameters = run\n",
    "\n",
    "        self.network = network\n",
    "        self.loader = loader\n",
    "        self.tb = SummaryWriter(comment= f'{run}')\n",
    "\n",
    "        images,label = next(iter(loader))\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "        self.tb.add_images(images,grid)\n",
    "        self.tb.add_graph(self.network,images)\n",
    "\n",
    "\n",
    "\n",
    "    def end_run(self):\n",
    "        self.tb.close()\n",
    "        self.epoch_count = 0    # the run is done for aparticular choice of hyperparameter so epochs will go to zero for the next run of other hyper parameters \n",
    "\n",
    "\n",
    "\n",
    "    #Now we define the methods for the begin epochs and end epochs\n",
    "\n",
    "\n",
    "    def begin_epoch(self):\n",
    "\n",
    "        self.epoch_start_time = time.time()\n",
    "        self.epoch_count += 1\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "\n",
    "    def end_epoch(self):\n",
    "\n",
    "        epoch_delay = time.time() - self.epoch_start_time\n",
    "        run_delay = time.time() - self.run_start_time\n",
    "        \n",
    "        loss = self.epoch_loss/len(self.loader.dataset)\n",
    "        accuracy =self.epoch_num_correct/len(self.loader.dataset)\n",
    "        self.tb.add_scaler(\"Loss\", loss , self.epoch_count)\n",
    "        self.tb.add_scaler(\"Acuracy\", accuracy , self.epoch_count)\n",
    "        \n",
    "        for name,param in self.network.named_parameters():\n",
    "            self.tb.add_histogram(name , param, self.epoch_count)\n",
    "            self.tb.add_histogram(f'{name}.grad' , param.grad, self.epoch_count)\n",
    "        \n",
    "        \n",
    "        results = OrderedDict()\n",
    "        results[\"run\"] = self.run_count\n",
    "        results[\"epoch\"] = self.epoch_count\n",
    "        results['loss'] = loss\n",
    "        results[\"accuracy\"] = accuracy\n",
    "        results['epoch duration'] = epoch_delay\n",
    "        results['run duration'] = run_delay\n",
    "        \n",
    "        for k,v in self.run_params._asdict().items(): results[k] = v   #we iterate over the keys and values inside our run parameters adding them to the results dictionary. This will allow us to see the parameters that are associated with the performance results.\n",
    "        self.run_data.append(results)\n",
    "        \n",
    "        df = pd.DataFrame.from_dicto(self.run_data,orient = 'columns')\n",
    "            \n",
    "        clear_output(wait=True)                #for jupyter notebook only\n",
    "        display(df)\n",
    "        \n",
    "\n",
    "    def track_loss(self,loss,batch):\n",
    "        self.epoch_loss += loss.item()*batch[0].shape[0]\n",
    "        \n",
    "        \n",
    "\n",
    "    def track_num_currect(self,preds,lables):\n",
    "        self.epoch_num_correct += self.get_num_correct(preds,labels)\n",
    "        \n",
    "\n",
    "        \n",
    "    def _get_num_correct(preds,labels):\n",
    "        return preds.argmax(dim =1).eq(labels).sum().item()\n",
    "    \n",
    "    \n",
    "    \n",
    "    def save(self, fileName):\n",
    "        pd.DataFrame.from_dict(\n",
    "            self.run_data, orient='columns'\n",
    "        ).to_csv(f'{fileName}.csv')\n",
    "\n",
    "        with open(f'{fileName}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.run_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8cb425f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "optimizer can only optimize Tensors, but one of the params is tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-bf767364fc14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmy_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmy_net\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad)\u001b[0m\n\u001b[1;32m     40\u001b[0m         defaults = dict(lr=lr, betas=betas, eps=eps,\n\u001b[1;32m     41\u001b[0m                         weight_decay=weight_decay, amsgrad=amsgrad)\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam_group\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_param_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36madd_param_group\u001b[0;34m(self, param_group)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_group\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 raise TypeError(\"optimizer can only optimize Tensors, \"\n\u001b[0m\u001b[1;32m    200\u001b[0m                                 \"but one of the params is \" + torch.typename(param))\n\u001b[1;32m    201\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_leaf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: optimizer can only optimize Tensors, but one of the params is tuple"
     ]
    }
   ],
   "source": [
    "params = OrderedDict(\n",
    "    lr = [.01]\n",
    "    ,batch_size = [1000, 2000]\n",
    ")\n",
    "epochs = 5\n",
    "m = RunManager()\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    my_net = Network()\n",
    "    loader = torch.utils.data.DataLoader(train_set, batch_size= run.batch_size)\n",
    "    optimizer = optim.Adam(my_net.named_parameters(), lr = run.lr)\n",
    "    \n",
    "    m.begin_run(run,my_net,loader)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        m.begin_epoch()\n",
    "        for batch in loader:\n",
    "            images,labels = batch\n",
    "            preds  = my_net(images)\n",
    "            loss = F.cross_entropy(preds,labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            m.track_loss(loss,batch)\n",
    "            m.track_num_currect(preds,labels)\n",
    "        m.end_epoch()\n",
    "    m.end_run()\n",
    "m.save('first_run_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5b4df69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'method'>\n"
     ]
    }
   ],
   "source": [
    "params = OrderedDict(\n",
    "    lr = [.01]\n",
    "    ,batch_size = [1000, 2000]\n",
    ")\n",
    "epochs = 5\n",
    "print(type(my_net.named_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1be3f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
