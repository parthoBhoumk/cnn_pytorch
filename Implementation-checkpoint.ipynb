{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25333581",
   "metadata": {},
   "source": [
    "\n",
    "# Implementation of cnn network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57007d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import pandas  as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "torch.set_printoptions(linewidth=120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ec4cddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#r\"\"\" taking a closer look into the network class\n",
    "\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network,self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels= 1, out_channels= 6 , kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels= 6, out_channels= 12 , kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features= 12*4*4 , out_features= 120)\n",
    "        self.fc2 = nn.Linear(in_features= 120, out_features= 60)\n",
    "        self.out = nn.Linear(in_features= 60, out_features= 10)\n",
    "\n",
    "    def forward(self,t):\n",
    "        \n",
    "        #1 inpput layer \n",
    "        \n",
    "        t = t\n",
    "        \n",
    "        #2 hidden conv layer\n",
    "        \n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size = 2 , stride = 2)\n",
    "        \n",
    "        #3 hidden conv layer \n",
    "        \n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size = 2 , stride = 2)\n",
    "        \n",
    "        #4 Linear layer \n",
    "        \n",
    "        t = t.reshape(-1, 12*4*4)     #flattening is hapening here\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "        \n",
    "        #5 Linear layer \n",
    "        \n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        #6 output layer\n",
    "        \n",
    "        t = self.out(t)\n",
    "        # t = F.softmax(t,dim = 0)    but this line is not required because we will predict the output later and softmax will be used explicitly later\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "574e7f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data from url of Mnist\n",
    "\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "        root = './data'\n",
    "        ,train = True\n",
    "        ,download=True\n",
    "        ,transform = transforms.Compose([\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f2c66166",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building my own network\n",
    "r\"\"\"\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1 , out_channels= 6, kernel_size= 5)\n",
    "        self.conv2= nn.Conv2d(in_channels=6, out_channels= 12,kernel_size= 5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60 , out_features= 10)\n",
    "        \n",
    "    def forward(self,t):\n",
    "        \n",
    "        t = F.relu(self.conv1(t))\n",
    "        t = F.max_pool2d(t,kernel_size= 2 , stride = 2)\n",
    "        \n",
    "        t = F.relu(self.conv2(t))\n",
    "        t = F.max_pool2d(t, kernel_size = 2 , stride= 2)\n",
    "        \n",
    "        t = F.relu(self.fc1(t.reshape(-1 , 12*4*4)))\n",
    "        t = F.relu(self.fc2(t))\n",
    "        t = self.out(t)                               \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "85d09cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mynet = Network()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8850e618",
   "metadata": {},
   "source": [
    "# Inspecting the output tensor for one image sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "61c26d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "sample = next(iter(train_set))\n",
    "image , label = sample\n",
    "image.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "17b88376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# but my neural network is expecting a rank 4 teensor and in this image there is no batch size given\n",
    "\n",
    "image.unsqueeze(0).shape # and we do it via unsquuze method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6fe6c2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = mynet(image.unsqueeze(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e5204e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fb87e48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0425,  0.0017, -0.1016,  0.0987, -0.0355,  0.0827, -0.0817, -0.0182, -0.0463, -0.1511]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2ff9bedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label   #what i am expecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c229e923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1062, 0.1020, 0.0920, 0.1124, 0.0983, 0.1106, 0.0938, 0.1000, 0.0972, 0.0875]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pred = F.softmax(pred,dim= 1)\n",
    "new_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "960b4a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pred.argmax()   #expected class representing 9 but got 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "192a9b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ea830a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.2087, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e39dd95",
   "metadata": {},
   "source": [
    "# passing an entire batch of images to my network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "84b9ce85",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(train_set,\n",
    "                    batch_size= 10                     \n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "75e6b37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "07ff3c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 28, 28])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images , labels = batch\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3a7f5527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this time the data is already in ranked 4 tensor so we dont need to squeeze anything \n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b1c4bd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = mynet(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "97ad0feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "71974adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1070, 0.0890, 0.1084, 0.0963, 0.0971, 0.1133, 0.0939, 0.0947, 0.1098, 0.0904],\n",
       "        [0.1069, 0.0892, 0.1082, 0.0960, 0.0979, 0.1137, 0.0939, 0.0948, 0.1094, 0.0900],\n",
       "        [0.1072, 0.0892, 0.1084, 0.0959, 0.0981, 0.1135, 0.0938, 0.0945, 0.1090, 0.0903],\n",
       "        [0.1071, 0.0892, 0.1083, 0.0959, 0.0980, 0.1136, 0.0939, 0.0945, 0.1092, 0.0904],\n",
       "        [0.1070, 0.0892, 0.1084, 0.0959, 0.0977, 0.1134, 0.0939, 0.0947, 0.1095, 0.0902],\n",
       "        [0.1066, 0.0891, 0.1084, 0.0961, 0.0979, 0.1139, 0.0939, 0.0950, 0.1092, 0.0898],\n",
       "        [0.1070, 0.0893, 0.1085, 0.0961, 0.0980, 0.1137, 0.0938, 0.0943, 0.1090, 0.0903],\n",
       "        [0.1070, 0.0890, 0.1083, 0.0962, 0.0972, 0.1135, 0.0941, 0.0952, 0.1095, 0.0900],\n",
       "        [0.1069, 0.0893, 0.1084, 0.0958, 0.0982, 0.1137, 0.0939, 0.0944, 0.1091, 0.0903],\n",
       "        [0.1065, 0.0891, 0.1087, 0.0956, 0.0983, 0.1145, 0.0934, 0.0946, 0.1092, 0.0901]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds =  F.softmax(preds, dim = 1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6eca413a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.argmax(1)   #possible output tensor with classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d5e0f5ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 0, 0, 3, 0, 2, 7, 2, 5, 5])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels   # expected output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "974c74a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False,  True,  True])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.argmax(dim = 1 ).eq(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f978fc13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.argmax(dim = 1).eq(labels).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ce941808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_currect_number(preds,labels):\n",
    "    \n",
    "    return preds.argmax(dim = 1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e45a7890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_currect_number(preds,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5995c03d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
